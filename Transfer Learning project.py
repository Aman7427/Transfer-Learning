# -*- coding: utf-8 -*-
"""DLASSIGNMENT3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x3NyjMtuv7OsZ9RuIeNPKpywiB_pIe8Z

#Assignment 3

Mount Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Importing Libararies"""

print("Importing Libraries that we will use for our Assignment :",)
import zipfile
import pandas as pd
import pathlib
import os
import numpy as np
from PIL import Image
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn as nn
import torchvision.models as models
import torch.nn.functional as F
import matplotlib.pyplot as plt
print("Imported Sucessfully")

"""#Extraction of Data

We have a zip folder that contains all the data like:
1. Train image
2. Train masks
3. Test image
4. Test masks
"""

print("Extract data form zip")
with zipfile.ZipFile("/content/drive/MyDrive/ISIC.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/")

"""# Pre-Processing and Data Loaders"""

class ISIC2016(Dataset):
    def __init__(self, image_path, mask_path, transform_image=None, transform_mask=None):
        self.image_path = image_path
        self.mask_path = mask_path
        self.transform_image = transform_image
        self.transform_mask = transform_mask
        self.image_files = sorted(os.listdir(self.image_path))
        self.mask_files = sorted(os.listdir(self.mask_path))

    def __len__(self):
        return len(self.image_files)  #,len(self.mask_files)

    def __getitem__(self, idx):
        title_image = os.path.join(self.image_path, self.image_files[idx])
        title_mask = os.path.join(self.mask_path, self.mask_files[idx])

        image = Image.open(title_image).convert('RGB')
        mask = Image.open(title_mask)

        if self.transform_image:
            image = self.transform_image(image)
        if self.transform_mask:
            mask = self.transform_mask(mask)
        return image, mask


# Set the directories for the data
train_image_path = '/content/train'
train_mask_path = '/content/train_masks'
test_image_path = '/content/test'
test_mask_path = '/content/test_masks'


# Define transforms for preprocessing
transform_image = transforms.Compose([transforms.Resize((128, 128)),transforms.ToTensor()])
transform_mask = transforms.Compose([transforms.Resize((128, 128)),transforms.ToTensor()])

# Define datasets
train_dataset = ISIC2016(image_path=train_image_path, mask_path=train_mask_path,transform_image = transform_image, transform_mask = transform_mask)
test_dataset = ISIC2016(image_path=test_image_path, mask_path=test_mask_path,transform_image = transform_image, transform_mask = transform_mask)


# Define dataloaders for training and testing
train_loader = DataLoader(train_dataset, batch_size=30, shuffle=True,num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=30, shuffle=False,num_workers=2)

print("Custom Dataloader are ready to use")

"""#Data Visulization"""

np.random.seed(42)
def visualize_dataset(dataset, num_samples):
    random_index = np.random.choice(len(dataset), size=num_samples)

    # Create a subplot grid
    fig, axes = plt.subplots(num_samples, 2, figsize=(15, 15))

    for i, index in enumerate(random_index):
      # plot the image
        image, mask = dataset[index]
        axes[i, 0].imshow(np.transpose(image.numpy(), (1, 2, 0)))
        axes[i, 0].set_title('Image')

        # Plot the mask
        axes[i, 1].imshow(mask.squeeze().numpy(), cmap='gray')
        axes[i, 1].set_title('Mask')
    plt.tight_layout()
    plt.show()


visualize_dataset(train_dataset,num_samples=5)

def plot_histogram(image, mask):
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    # Plotting histogram of pixel intensities for image
    axes[0].hist(image.flatten(), bins=50, color='blue')
    axes[0].set_title('Image Pixel Intensity Histogram')
    axes[0].set_xlabel('Pixel Intensity')
    axes[0].set_ylabel('Frequency')

    # Plot histogram of pixel intensities for mask
    axes[1].hist(mask.flatten(), bins=50, color='red')
    axes[1].set_title('Mask Pixel Intensity Histogram')
    axes[1].set_xlabel('Pixel Intensity')
    axes[1].set_ylabel('Frequency')

    plt.tight_layout()
    plt.show()

# A random sample from the training dataset
random_idx = np.random.randint(len(train_dataset))
sample_image, sample_mask = train_dataset[random_idx]

# Plot histograms
plot_histogram(sample_image.numpy(), sample_mask.numpy())

"""#Shape of Dataloaders(Image,masks)"""

print("Training Data:")
for images, masks in train_loader:
    print("Image shape in training data:",images.shape)
    print("Mask shape in training data:",masks.shape)
    break
print("Testing Data:")
for images, masks in test_loader:
    print("Image shape in testing data:",images.shape)
    print("Mask shape in testing data:",masks.shape)
    break

"""#Model 1"""

class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()

        self.conv1 = nn.ConvTranspose2d(1280, 512, kernel_size=4, stride=2, padding=1)
        self.dropout1 = nn.Dropout2d(p=0.5)
        self.conv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, padding=1)
        self.dropout2 = nn.Dropout2d(p=0.5)
        self.conv3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)
        self.dropout3 = nn.Dropout2d(p=0.5)
        self.conv4 = nn.ConvTranspose2d(128, 1, kernel_size=3, padding=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.dropout1(x)
        x = self.conv2(x)
        x = self.dropout2(x)
        x = self.conv3(x)
        x = self.dropout3(x)
        x = self.conv4(x)
        x = torch.nn.functional.interpolate(x, size=(128, 128), mode='bilinear', align_corners=False)
        return x

decoder = Decoder()
# Define the segmentation model
class model_segmentation(nn.Module):
    def __init__(self, encoder, decoder):
        super(model_segmentation, self).__init__()
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, x):
        features = self.encoder.features(x)
        segmentated_mask = self.decoder(features)
        return segmentated_mask

print("Pre-trained MobileNetV2 as encoder:")
encoder = models.mobilenet_v2(pretrained=True)

for param in encoder.parameters():
    param.requires_grad = False
print("Here the parameters of the encoder are freezed")

model = model_segmentation(encoder, decoder)
loss_function = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss for segmentation
optimizer = torch.optim.NAdam(model.parameters(), lr=0.001)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

def iou_score(True_mask, predicated_mask):
    intersection = np.logical_and(True_mask, predicated_mask).sum()
    union = np.logical_or(True_mask, predicated_mask).sum()
    iou_score = intersection / (union + 1e-6)
    return iou_score

def dice_score(True_mask, predicated_mask):
    intersection = np.sum(True_mask * predicated_mask)
    union = np.sum(True_mask) + np.sum(predicated_mask)
    dice = (2. * intersection) / union
    return dice

"""# Training of the model"""

def train(model, loss_function, optimizer, train_loader, device):
    model.train()
    loss_value = 0.0
    for images, masks in train_loader:
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_function(outputs, masks)
        loss.backward()
        optimizer.step()
        loss_value += loss.item() * images.size(0)
    epoch_loss = loss_value / len(train_loader.dataset)
    return epoch_loss

def test(model, loss_function, test_loader, device):
    model.eval()
    loss_value = 0.0
    iou_score_value = 0.0
    dice_score_value = 0.0
    with torch.no_grad():
        for images, masks in test_loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            loss = loss_function(outputs, masks)
            loss_value += loss.item() * images.size(0)
            predicted_masks = outputs.sigmoid().cpu().numpy()
            masks = masks.cpu().numpy()
            iou_score_value += iou_score(masks, predicted_masks)
            dice_score_value += dice_score(masks, predicted_masks)
    epoch_loss = loss_value / len(test_loader.dataset)
    mean_iou_score = iou_score_value / len(test_loader)
    mean_dice_score = dice_score_value / len(test_loader)
    return epoch_loss, mean_iou_score, mean_dice_score

num_epochs = 25

training_losses = []
testing_losses = []
testing_iou_scores = []
testing_dice_scores = []

for epoch in range(num_epochs):
    train_loss = train(model, loss_function, optimizer, train_loader, device)
    test_loss, test_iou, test_dice = test(model, loss_function, test_loader, device)

    training_losses.append(train_loss)
    testing_losses.append(test_loss)
    testing_iou_scores.append(test_iou)
    testing_dice_scores.append(test_dice)

    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test IoU: {test_iou:.4f}, Test Dice: {test_dice:.4f}")

# Plotting the losses
plt.plot(range(1, num_epochs+1), training_losses, label='Train Loss')
plt.plot(range(1, num_epochs+1), testing_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Testing Loss')
plt.legend()
plt.show()

def visualize_samples(model, test_loader, device):
    model.eval()
    with torch.no_grad():
        for i, (images, masks) in enumerate(test_loader):
            if i == 10:
                break
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            predicted_masks = outputs.sigmoid()
            for j in range(images.size(0)):
                image_np = images[j].cpu().permute(1, 2, 0).numpy()
                mask_np = masks[j].cpu().numpy().squeeze()
                predicted_mask_np = predicted_masks[j].cpu().squeeze().numpy()

                plt.figure(figsize=(15, 5))
                plt.subplot(1, 3, 1)
                plt.imshow(image_np)
                plt.title('Image')

                plt.subplot(1, 3, 2)
                plt.imshow(mask_np, cmap='gray')
                plt.title('Ground Truth')

                plt.subplot(1, 3, 3)
                plt.imshow(predicted_mask_np, cmap='gray')
                plt.title('Predicted Mask')


                plt.show()

visualize_samples(model, test_loader, device)

"""# Model 2"""

class Decoder2(nn.Module):
    def __init__(self):
        super(Decoder2, self).__init__()
        self.conv1 = nn.ConvTranspose2d(1280, 512, kernel_size=4, stride=2, padding=1)
        self.dropout1 = nn.Dropout2d(p=0.5)
        self.conv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, padding=1)
        self.dropout2 = nn.Dropout2d(p=0.5)
        self.conv3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)
        self.dropout3 = nn.Dropout2d(p=0.5)
        self.conv4 = nn.ConvTranspose2d(128, 1, kernel_size=3, padding=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.dropout1(x)
        x = self.conv2(x)
        x = self.dropout2(x)
        x = self.conv3(x)
        x = self.dropout3(x)
        x = self.conv4(x)
        x = torch.nn.functional.interpolate(x, size=(128, 128), mode='bilinear', align_corners=False)
        return x

class model_segmentation2(nn.Module):
    def __init__(self, encoder2, decoder2):
        super(model_segmentation2, self).__init__()
        self.encoder2 = encoder2
        self.decoder2 = decoder2

    def forward(self, x):
        features = self.encoder2.features(x)
        segmentated_mask = self.decoder2(features)
        return segmentated_mask

# Load pre-trained MobileNetV2 encoder
encoder2 = models.mobilenet_v2(pretrained=True)

# Now here parameters are not freezed
for param in encoder2.parameters():
    param.requires_grad = True

decoder2 = Decoder2()
model2 = model_segmentation2(encoder2, decoder2)
loss_function2 = nn.BCEWithLogitsLoss()
optimizer2 = torch.optim.NAdam([
    {'params': model2.encoder2.parameters()},
    {'params': model2.decoder2.parameters()}
], lr=0.001)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model2.to(device)

def train(model2, loss_function2, optimizer2, train_loader, device):
    model2.train()
    loss_value = 0.0
    for images, masks in train_loader:
        images, masks = images.to(device), masks.to(device)
        optimizer2.zero_grad()
        outputs = model2(images)
        loss = loss_function2(outputs, masks)
        loss.backward()
        optimizer2.step()
        loss_value += loss.item() * images.size(0)
    epoch_loss = loss_value / len(train_loader.dataset)
    return epoch_loss

def validate(model2, loss_function2, test_loader, device):
    model2.eval()
    loss_value = 0.0
    iou_score_value = 0.0
    dice_score_value = 0.0
    with torch.no_grad():
        for images, masks in test_loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model2(images)
            loss = loss_function2(outputs, masks)
            loss_value += loss.item() * images.size(0)
            predicted_masks = outputs.sigmoid().cpu().numpy()
            masks = masks.cpu().numpy()
            iou_score_value += iou_score(masks, predicted_masks)
            dice_score_value += dice_score(masks, predicted_masks)
    epoch_loss = loss_value / len(test_loader.dataset)
    mean_iou_score = iou_score_value / len(test_loader)
    mean_dice_score = dice_score_value / len(test_loader)
    return epoch_loss, mean_iou_score, mean_dice_score

num_epochs = 25

training_losses = []
testing_losses = []
testing_iou_scores = []
testing_dice_scores = []

for epoch in range(num_epochs):
    train_loss = train(model2, loss_function2, optimizer2, train_loader, device)
    test_loss, test_iou, test_dice = test(model2, loss_function2, test_loader, device)

    training_losses.append(train_loss)
    testing_losses.append(test_loss)
    testing_iou_scores.append(test_iou)
    testing_dice_scores.append(test_dice)

    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test IoU: {test_iou:.4f}, Test Dice: {test_dice:.4f}")

# Plotting the losses
plt.plot(range(1, num_epochs+1), training_losses, label='Training Loss')
plt.plot(range(1, num_epochs+1), testing_losses, label='Testing Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Testing Loss')
plt.legend()
plt.show()

def visualize_samples(model2, test_loader, device,num_samples=30):
    model2.eval()
    with torch.no_grad():
        for i, (images, masks) in enumerate(test_loader):
            if i == num_samples:
                break
            images, masks = images.to(device), masks.to(device)
            outputs = model2(images)
            predicted_masks = outputs.sigmoid()
            for j in range(images.size(0)):
                image_np = images[j].cpu().permute(1, 2, 0).numpy()
                mask_np = masks[j].cpu().numpy().squeeze()  # Remove singleton dimension
                predicted_mask_np = predicted_masks[j].cpu().squeeze().numpy()

                plt.figure(figsize=(15, 5))
                plt.subplot(1, 3, 1)
                plt.imshow(image_np)
                plt.title('Image')
                plt.axis('off')

                plt.subplot(1, 3, 2)
                plt.imshow(mask_np, cmap='gray')
                plt.title('Ground Truth Mask')
                plt.axis('off')

                plt.subplot(1, 3, 3)
                plt.imshow(predicted_mask_np, cmap='gray')
                plt.title('Predicted Mask')
                plt.axis('off')

                plt.show()

visualize_samples(model2, test_loader, device)

